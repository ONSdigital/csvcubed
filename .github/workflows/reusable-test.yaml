name: Test csvcubed
on:
  workflow_call:
    inputs:
      os:
        required: true
        type: string
      python-version:
        required: true
        type: string
      pandas-version:
        required: true
        type: string

jobs:
  test_in_environments:
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      # Necessary for running csvlint inside the Windows VM. TODO: REMOVE THIS

      - name: Install csvlint, csv2rdf and sparql-test-runner (Windows)
        id: windows-install
        if: inputs.os == 'windows-latest'

        run: .\windows-testing-setup.ps1 -verbose
        shell: pwsh

      - uses: actions/setup-python@v4
        id: install-python
        with:
          python-version: ${{ inputs.python-version }}

      - uses: actions/setup-node@v3
        with:
          node-version: 16

      - name: Install pyright
        run: npm install -g pyright@1.1.302

      - name: Install markdown spell-checker
        run: npm install -g spellchecker-cli

      - name: Test spelling in external docs
        run: cd external-docs && bash spell-check.sh

      - name: Install poetry
        run: pip install poetry

      - uses: actions/cache@v3
        # Include pandas version in cache key for Ubuntu/Python 3.11
        if: inputs.os == 'ubuntu-latest' && inputs.python-version == '3.11'
        with:
          path: |
            ~/.cache/pypoetry/virtualenvs
            C:\Users\runneradmin\AppData\Local\pypoetry\Cache\virtualenvs
          key: ${{ inputs.os }}-${{ steps.install-python.outputs.python-version }}-poetry-${{ hashFiles('poetry.lock') }}-${{ inputs.pandas-version }}

      - uses: actions/cache@v3
        if: (inputs.os == 'ubuntu-latest' && inputs.python-version == '3.9') || inputs.os == 'windows-latest'
        with:
          path: |
            ~/.cache/pypoetry/virtualenvs
            C:\Users\runneradmin\AppData\Local\pypoetry\Cache\virtualenvs
          key: ${{ inputs.os }}-${{ steps.install-python.outputs.python-version }}-poetry-${{ hashFiles('poetry.lock') }}-

      - name: Install python packages
        run: poetry install --sync

      - name: Specify pandas version (Ubuntu & Python 3.11)
        if: inputs.os == 'ubuntu-latest' && inputs.python-version == '3.11' && inputs.pandas-version != ''
        run: poetry add ${{ inputs.pandas-version }}

      - name: Run pyright
        run: poetry run pyright . --lib

      - name: Ensure ValidatedModel properties have validations provided
        run: poetry run python tests/pref_improvement/pref_check.py

      - name: Run unittests
        run: poetry run pytest --junitxml=pytest_results.xml

      - name: Run behaviour tests (Windows)
        if: inputs.os == 'windows-latest'
        run: |
          $csv2rdfLocation = "${{ steps.windows-install.outputs.CSV2RDF_LOCATION }}"
          $sparqlTestsDir = "${{ steps.windows-install.outputs.SPARQL_TESTS_LOCATION }}"

          $env:NO_DOCKER="true"; $env:CSV2RDF="$csv2rdfLocation"; $env:SPARQL_TESTS_DIR="$sparqlTestsDir"; poetry run behave tests/behaviour --tags=-skip --junit --format progress
        shell: pwsh

      - name: Run behaviour tests (Ubuntu)
        if: inputs.os == 'ubuntu-latest'
        run: poetry run behave tests/behaviour --tags=-skip --junit --format progress

      - name: Archive unit & behave test results from xml files
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: ${{ inputs.os }}-python${{ inputs.python-version }}-${{ inputs.pandas-version }} behave test results
          path: |
            pytest_results.xml
            reports/*.xml

  publish_test_results:
    needs: [test_in_environments]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/download-artifact@v3
        with:
          name: ${{ inputs.os }}-python${{ inputs.python-version }}-${{ inputs.pandas-version }} behave test results

      - name: Remove broken characters from xml test files
        # By removing broken characters from the xml unit/behave test files, we can then publish the tests results stored
        # in those files in a user friendly way on github actions using 'EnricoMi/publish-unit-test-result-action@v1'.
        if: always()
        run: sed -i -e "s/[\\x0A\\x1B]//g" reports/TESTS-*.xml

      - name: Publish Unit & Behave Test Results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          check_name: ${{ inputs.os }}-python${{ inputs.python-version }}-${{ inputs.pandas-version }} test results
          junit_files: |
            reports/*.xml
            pytest_results.xml
